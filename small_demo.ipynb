{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#127794; Digital Champion - Python Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#128210; Inhaltsverzeichnis:\n",
    "* [1 Einführung](#first-bullet)\n",
    "* [2 Entscheidungsbäume Theorie & Aufgabenstellung](#first-bullet)\n",
    "* [3 Datenaufbereitung](#third-bullet)\n",
    "* [4 Einfacher Entscheidungsbaum](#fourth-bullet)\n",
    "* [5 Datenaufbereitung](#fifth-bullet)\n",
    "* [6 Abschluss](#sixth-bullet)\n",
    "* [7 Anhang](#seventh-bullet)\n",
    "* [8 Lösungen](#eight-bullet)\n",
    "* [9 Quellen](#nineth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Einführung (5 min) <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks sind interaktive Entwicklungsumgebungen, die es ermöglichen, Code, Visualisierungen und Text in einer einzigen Umgebung zu kombinieren. Sie werden häufig für die Datenanalyse, den Code-Austausch und die Dokumentation verwendet. Mit Jupyter Notebooks können Python-Codezellen ausgeführt und die Ergebnisse sofort angezeigt werden. In diesem Jupyter-Notebook werden wir ```Entscheidungsbäume``` betrachten.\n",
    "\n",
    "![alt text for screen readers](./pictures/jupyter_intro.png \"Einführung Jupyter Notebook\").\n",
    "\n",
    "### Erklärungen:\n",
    "- &#128190; **Speichern:** Mit diesem Symbol können wir wir das Notebook und alle Änderungen speichern\n",
    "* &#10133; **Hinzufügen einer neuen Zelle:** Mit diesem Symbol können wir eine neue Zelle in das Notebook einfügen\n",
    "* &#9986; **Löschen:** Mit diesem Symbol können wir eine Zelle löschen und deren Inhalt entfernen\n",
    "* &#9654; **Ausführen:** Mit diesem Symbol können wir den Code in einer Zelle ausführen\n",
    "* ```Cell``` -> ```Run all above``` Es kann sein, dass der Kernel nicht mehr verbunden ist. In diesem Fall müssen wir den Kernel neustarten und alle Zellen neu laufen lassen\n",
    "* ```Markdown``` Markdown-Zellen dienen zur Eingabe und Formatierung von Text. Sie ermöglichen es, Text, Überschriften, Aufzählungen, Bilder und andere Formatierungselemente einzufügen\n",
    "* ```Code``` Code-Zellen werden verwendet, um ausführbaren Code einzugeben. In einer Code-Zelle können Programmiersprachen wie Python, R, Julia und andere verwendet werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b> \n",
    "\n",
    "- Wir lesen das Notebook durch und bearbeiten die Aufgaben direkt in diesem Notebook\n",
    "    \n",
    "- Die Lösungen können wir mit dem Link unter den Aufgaben aufrufen\n",
    "    \n",
    "- Fragen bitte direkt in den Chat schreiben\n",
    "\n",
    "- Komplexere Fragen werden in Breakout-Sessions behandelt\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Entscheidungsbäume Theorie & Aufgabenstellung (8 min) <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Was ist ein Entscheidungsbaum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entscheidungsbäume sind eine Methode zur automatischen Klassifizierung von Datenobjekten (z.B. Personen etc.) und damit zur Lösung von Entscheidungsproblemen. Ein Entscheidungsbaum besteht immer aus einem Wurzelknoten (root node) und beliebig vielen inneren Knoten (split node) sowie mindestens zwei Blättern (leaf node). Dabei repräsentiert jeder Knoten eine logische Regel und jedes Blatt eine Antwort auf das Entscheidungsproblem. Im Folgenden ist ein Beispiel für einen Entscheidungsbaum abgebildet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/dt-example-new.png \"Beispiel Entscheidungsbaum\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem abgebildeten Entscheidungsbaum wollen wir mit den Informationen von ```income_usd``` und ```with_mortage``` herausfinden, ob eine Person eine Versicherung hat.\n",
    "\n",
    "Die folgenden Informationen sind üblicherweise im Entscheidungsbaum abgebildet:\n",
    "* **gini:** Der Gini-Index beschreibt, wie gut ein Knoten verschiedene Klassen (z.B. ```No Insurance```, ```Has Insurance```) separiert. Der Wert ist immer zwischen 0 und 1. Je kleiner der Gini-Index ist desto besser. Bei der Konstruktion des Entscheidungsbaumes kann der Gini-Index berechnet werden. Es wird immer die logische Regel gewählt, welche den besten Gini-Index aufweist.\n",
    "* **samples:** Dieser Wert beschreibt die Anzahl Beobachtungen (z.B. Daten von Personen), welche für den Split eines spezifischen Knoten zur Verfügung stehen. Wir sehen beispielsweise, dass für die Konstruktion dieses Baumes Daten von 24 Personen verwendet wurden. Weiter sehen wir, dass der erste Knoten die 24 Personen in eine Gruppe mit 13 und eine Gruppe mit 11 Personen aufteilt.\n",
    "* **value:** Value beschreibt, wie die Aufteilung der ```samples``` im Knoten aussieht. Der Wert ```[15, 9]``` im ersten Knoten beschreibt beispielsweise, dass von 24 Personen 15 keine Versicherung und 9 Personen eine Versicherung haben.\n",
    "* **class:** Dieser Wert steht für die Klasse, für welche ein spezifischer Knoten steht. Beispiel: Im ersten Knoten sehen wir, die Klasse ```No insurance```, da von den 24 Personen mehr ```No Insurance``` (15) haben, als ```Has Insurance``` (9). Anhand der Farbe kann ebenfalls die Klasse abgelesen werden. Je röter ein Knoten ist, je mehr gehört er zur Klasse ```No Insurance``` und je blauer ein Knoten ist, je mehr gehört er zur Klasse ```Has Insurance```.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b> \n",
    "Wie kann man einen Entscheidungsbaum lesen bzw. wie klassifizert der Entscheidungsbaum neue Beobachtungen (z.B. Personen):\n",
    "\n",
    "- Wir starten immer beim Wurzelknoten, d.h. ganz oben im Entscheidungsbaum\n",
    "\n",
    "- Wenn die logische Regel im Knoten für die neue Beobachtung erfüllt ist, geht man nach links und wenn sie nicht erfüllt ist, geht man nach rechts\n",
    "\n",
    "- Wir durchlaufen den Baum so lange, bis wir bei einem Blatt ankommen. Das ```class``` Attribute im Blatt beschreibt die Klasse des neuen Datenobjekts \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 1:</b> Bestimme die Klasse der beiden nachfolgeden Personen anhand des oben abgebildeten Entscheidungsbaums:\n",
    "\n",
    "- Person 1: income_usd = 100'000; with_mortage = 0\n",
    "\n",
    "- Person 2: income_usd = 73'000; with_mortage = 1\n",
    "\n",
    "-> Lösungen zu [Aufgabe 1](#lösung_aufgabe_1)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung (mit # Kommentarfunktion):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Aufgabenstellung\n",
    "\n",
    "In diesem Jupyter-Notebook arbeiten wir mit dem ['heart-disease'](https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/) (HD) Datenset. Das Datenset ist eine Tabelle mit 14 Spalten (Features) und 303 Zeilen (Beobachtungen). Eine kurze Beschreibung der verschiedenen Features:\n",
    "* age: Alter\n",
    "* sex: Mann/Frau\n",
    "* restbp: resting blood pressure (Ruheblutdruck (in mm Hg bei Aufnahme ins Krankenhaus))\n",
    "* chol: Serumcholesterin in mg/dl\n",
    "* fbs: wenn der Nüchternblutzucker > 120 mg/dl liegt\n",
    "* thalach: maximale Herzfrequenz erreicht\n",
    "* exang: Belastungsangina (Richtig/Falsch)\n",
    "* oldpeak: ST-Depression durch körperliche Betätigung im Vergleich zur Ruhe\n",
    "* ca: Anzahl der großen Gefäße (0-3), gefärbt durch Fluoroskopie\n",
    "* hd: Art der Herzerkrankung\n",
    "\n",
    "Unser Ziel ist es, mit den 303 Beobachtungen ein Modell zu generieren, welches neue Beobachtungen (bzw. Personen) klassifizieren und somit bestimmen kann, ob eine Herzerkrankung (HD) vorliegt oder nicht. Im Modell nutzen wir die oben beschriebenen Features um die Zielvariable (HD) vorherzusagen:\n",
    "\n",
    "Wir verwenden einen Entscheidungsbaum für die Klassifikation von HD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Datenaufbereitung (12 min) <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Read data\n",
    "\n",
    "Bei jedem neuen Python-Projekt überlegen wir uns, welche Python-Bibliotheken wir verwenden möchten. Eine Python-Bibliothek ist ein wiederverwendbarer Codeblock, den wir in einem Programm bzw. Projekt einbinden können. Das Einbinden von solchen Codeblocks ist einiges schneller als den Code selber zu schreiben.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b> \n",
    "Wenn wir in Python programmieren, ist es wichtig zu wissen, dass alles was hinter einem '#' steht kein Code ist, sondern nur ein Kommentar um den Code zu beschreiben. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install pandas numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "# pandas: Daten lesen und bearbeiten\n",
    "import pandas as pd\n",
    "# numpy: berechnen von KPIs\n",
    "import numpy as np\n",
    "# plt: ploten von Grafiken\n",
    "import matplotlib.pyplot as plt\n",
    "# DecisionTreeClassifier: Modellierungskit für Entscheidungsbäume\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# plot_tree: Entscheidungsbaum als Grafik ploten\n",
    "from sklearn.tree import plot_tree\n",
    "# train_test_split: Hilfe um Testobjekte in Training- bzw. Testset zu splitten\n",
    "from sklearn.model_selection import train_test_split\n",
    "# cross_val_score: Kreuzvalidierung\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# confusion_matrix: Konfusionsmatrix ploten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# ConfusionMatrixDispla: Konfusionsmatrix ploten\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# accuracy_score: berechne die Accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b>  In Python kann man mit Hilft des '=' Operatros Daten in einer Variable speichern. Wenn wir beispielsweise die Zahl 5 in der Variable 'a' speichern möchten, können wir das mit dem folgenden Code machen:\n",
    "<br><br>\n",
    "a = 5 \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(filepath_or_buffer, sep, encoding) ermöglicht es '.csv' Daten einzulesen\n",
    "# und in einer Variable als Tabelle zu speichern\n",
    "df = pd.read_csv(filepath_or_buffer='data/processed_cleveland_small.csv',\n",
    "                 sep=',',\n",
    "                 encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wenn wir eine Variable aufrufen, wird sie geplottet\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 2:</b> \n",
    "Speichere die Daten in der Variable 'df_start'\n",
    "    \n",
    "-> Lösungen zu [Aufgabe 2](#lösung_aufgabe_2)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head() zeigt, wie die ersten fünf Spalten in der Tabelle aussehen\n",
    "df_start.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fehlenden Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir den Spaltennamen in eckige Klammer schreiben, z.B. ['Spaltenname'], erhalten wir die Werte dieser Spalte\n",
    "df_start['ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der letzte geplotete Wert ist ein '?'. Wir wollen kurz prüfen, ob es noch mehr solche 'speziellen' Werte gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .unique() zeigt allte einzigartigen Elemente in der Spalte 'ca'\n",
    "df_start['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da '?' der einzige 'spezielle' Werte in der Spalte ist, nehmen wir an, es sind fehlende Daten.\n",
    "\n",
    "Um zu sehen, wie viel mal dieser Wert vorkommt, filtern wir danach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Tabellenname['Spaltenname'] == 'zu prüfender Text'] so kann eine Tabelle nach einem spezifischen Spaltenwert gefiltert werden\n",
    "df_start[df_start['ca'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Wert '?' kommt nur wenige Male vor. Aus diesem Grund entfernen wir jede Beobachtung mit einem Fragezeichn. Fehlende Daten können zu Fehleren in der Konstruktion von Entscheidungsbäumen führen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b> Die wichtigsten Vergleichsoperatoren:\n",
    "    \n",
    "* ==: zu vergleichendes Element muss den gleichen Inhalt haben\n",
    "* !=: zu vergleichendes Element darf nicht den gleichen Inhalt haben\n",
    "* \\>=: zu vergleichende Zahl muss gleich grösser sein\n",
    "* <=: zu vergleichende Zahl muss gleich kleiner sein\n",
    "     \n",
    "     </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 3:</b> \n",
    "Wir haben gesehen, dass nur 4 Testobjekte in der Spalte 'ca' ein '?' enthalten. Weil es nur so wenige Testobjekte sind, wollen wir diese aus unserer 'df_start' Tabelle rausfiltern und die neue Tabelle unter 'df_no_missing' speichern.\n",
    "\n",
    "-> Lösungen zu [Aufgabe 3](#lösung_aufgabe_3)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier prüfen wir, ob wir alle '?' entfernt haben\n",
    "df_no_missing['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ausreisser\n",
    "\n",
    "Bei dem folgenden Feature vermuten wir Ausreisser (Outliers):\n",
    "* age\n",
    "\n",
    "Eine Möglichkeit Daten auf Ausreisser zu prüfen sind Boxplots. Boxplots zeigen wie die Daten verteilt sind.\n",
    "\n",
    "![alt text for screen readers](./pictures/boxplot-new.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .boxplot(Spaltenname) plottet einen Boxplot einer Tabellenspalte\n",
    "df_no_missing.boxplot('age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass es im Feature ```age``` keine Ausreisser hat. Falls Ausreisser vorkommen, sollte man diese entfernen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Daten formatieren\n",
    "In einem nächsten Schritt müssen wir die Daten zweiteilen. Alle Features kommen in die Tabelle ```X```. Die Werte der Zielvariablen kommen in die Tabelle ```y```.\n",
    "\n",
    "```X``` stellt potentielle Beobachtungen (Daten von Personen) dar und ```y``` steht für die potentiellen Klassifizierungen (```0```=```keine HD```; ```1```=```hat HD```).\n",
    "\n",
    "Das Ziel wird es später sein, einen Entscheidungsbaum zu konstruieren welcher ```y``` möglichst richtig klassifiziert in Abhängigkeit von ```X```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit .copy() kopieren wir eine Variable in eine neue Variable\n",
    "df_clean = df_no_missing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in diesem Schritt speichern wir alle Features in 'X'\n",
    "# .drop('Spaltenname', axis=1) kann verwendet werden um eine Spalte zu entfernen\n",
    "# mit .copy() kopieren wir das Resultat in eine neue Variable\n",
    "X = df_clean.drop('hd', axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in diesem Schritt speichern wir alle Zielvariablen in 'y'\n",
    "y = df_clean['hd'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten Schritt unterteilen wir unsere Daten in ein ```Trainings-``` und in ein ```Testset```:\n",
    "- ```Trainingsset```: Wird verwendet, um einen Entscheidungsbaum abhängig von spezifische Beobachtungen zu konstruieren (bzw. trainieren) und ihm die spezifischen Eigenschaften eines Datensatzes mit Beobachtungen beizubringen\n",
    "- ```Testset```: Wird verwendet, um den Entscheidungsbaum zu testen und zu kontrollieren, wie gut er neue Beobachtungen klassifizieren kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split(X, y) teilt die Daten in ein Trainings- und in ein Testset\n",
    "# Standardmäßig sind im Testset 25% der Daten vorhanden und im Trainingsset 75%\n",
    "# wir sehen, dass train_test_split() 4 Tabellen generiert (je ein X und y Tabelle für beide Sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Einfacher Entscheidungsbaum (10 min) <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "### 4.1 Einfacher Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt konstruieren wir einen ```einfachen Entscheidungsbaum``` (ohne Optimierungen) abhängig von unseren Beobachtungen im Trainingsset.\n",
    "\n",
    "Im nächsten Abschnitt konstruieren wir einen ```opitmierten Entscheidungsbaum``` abhängig von unseren Beobachtungen im Trainingsset und vergleichen diesern mit dem ```einfachen Entscheidungsbaum```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTressClassifier() übernimmt für uns das erstellen eines Entscheidungsbaumes\n",
    "clf_dt_e = DecisionTreeClassifier(random_state=42)\n",
    "# .fit(X_train, y_train) weist dem Entscheidungsbaum ein Trainingsset (X und y) zu\n",
    "clf_dt_e.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mit den folgenden Zeilen können wir einen Entscheidungsbaum plotten\n",
    "# hier wird die grösse des plotts definiert (15 steht für die Breite und 7.5 steht für die Höhe)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "# plot_tree(decision_tree, class_names, feature_names) übernimmt das visualisieren eines Entscheidungsbaumes für uns\n",
    "# 'decision_tree' steht für den Entscheidungsbaum der visualisiert werden soll\n",
    "plot_tree(decision_tree=clf_dt_e,\n",
    "          # 'filled=True' so werden die Knoten mit Farben gefüllt\n",
    "          filled=True,\n",
    "          # 'class_names=[\"kein HD\", \"hat HD\"]' Klassen die in jedem Knoten unter 'class' stehen sollen\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          # 'feature_names=X.columns' muss mitgegeben werden, dass die Features im Plot korrekt bezeichnet werden\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem ersten Schritt haben wir einen Entscheidungsbaum gebaut. Jetzt wollen wir sehen, wie gut dieser Entscheidungsbaum, welchen wir mit den Trainingsset trainiert haben, Klassifizierungen im Testset vornehmen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .predict(Tabellenname) kann für Klassifizierungen gebraucht werden\n",
    "# als Input muss dieser Funktion ein Tabellenname mitgegeben werden -> die Tabelle muss die Test-Features enthalten\n",
    "predictions = clf_dt_e.predict(X_test)\n",
    "# der Output ist eine Liste mit den Klassifizierungen (0=keine HD; 1=hat HD)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt wollen wir prüfen, ob diese Klassifizierungen richtig oder falsch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_true, y_pred, labels) bietet uns eine Möglichkeit für so eine Prüfung\n",
    "# 'y_true' -> Liste der korrekten Klassifizierungen\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      # 'y_pred' -> Liste der vogenommenen Klassifizierungen\n",
    "                      y_pred=predictions,\n",
    "                      # 'labels' -> Klassen von clf_dt mitgeben\n",
    "                      labels=clf_dt_e.classes_)\n",
    "\n",
    "# ConfusionMatrixDisplay(confusion_matrix, display_labels) ist eine Möglichkeit die Confusion-Matrix 'cm' zu visualisieren\n",
    "# 'confusion_matrix' -> Confusion-Matrix die visualisiert werden soll\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              # 'display_labels' -> welche Labels sollen auf der Visualisierung dargestellt werden\n",
    "                              display_labels=['keine HD', 'hat HD'])\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die oben abgebildete Grafik zeigt eine ```Confusion-Matrix```. Wie lesen wir diese:\n",
    "- 31: Haben keine Herzkrankheit -> Diese 31 haben wir korrekt klassifiziert (True Negative TN) <br>\n",
    "- 12: Haben keine Herzkrankheit -> Diese 12 haben wir falsch klassifiziert (False Negative FN) <br>\n",
    "- 25: Haben eine Herzkrankheit -> Diese 25 haben wir korrekt klassifiziert (True Positive TP) <br>\n",
    "- 7: Haben eine Herzkrankheit -> Diese 7 haben wir falsch klassifiziert (False Positive FP)\n",
    "\n",
    "Wie gut ein Entscheidungsbaum ist, definieren wir anhand der ```Accuracy```. Welche mit Hilfe der ```Confusion-Matrix``` berechnet werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b>\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "<br>\n",
    "<br>... bei unserem einfachen Entscheidungsbaum haben wir z.B. folgende Precision:\n",
    "<br> \n",
    "<br>Accuracy = (25 + 31) / (25 + 31 + 7 + 12) = 0.75\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_true, y_pred) liefert ebenfalls die korrekte Accuracy\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Optimierter Entscheidungsbaum (10 min) <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "### 5.1 Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/ccp.png \"Pruning\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben einen ```einfachen Entscheidungsbaum``` konstruiert. Dieser Entscheidungsbaum ist auf unser Trainigsset überangepasst. Das heisst, er funktioniert sehr gut für die Klassifizierung von Beobachtungen aus unserem Trainigsset aber weniger gut für die Klassifizierung von neuen Beobachtungen.\n",
    "\n",
    "Dieses Problem können wir lösen, indem wir verschiedene Arten von Parametern verwenden (z. B. ```max_ Depth``` oder ```min_samples```) und den Entscheidungsbaum optimieren bzw. vereinfachen (weniger Blätter). Diesen Prozess nennt man ```Pruning```.\n",
    "\n",
    "```Pruning``` sollte die ```Accuracy``` im Bezug auf neue Beobachtungen verbessern.\n",
    "\n",
    "```Cost Complexity Pruning``` ist eine spezifische Methode, um einen kleineren Baum zu finden, der bessere Ergebnisse mit neuen Beobachtungen liefert. Wir schauen, ob kleinere Teil-Entscheidungsbäume (Baum mit 38 Blätter, Baum mit 37 Blätter, etc.) bessere Ergebnisse liefern als grössere. Damit kleinere Bäume mit grösseren Bäumen verglichen werden können, verwenden wir ```alpha``` als eine Art Penalty, der das Ergebniss von kleineren Bäumen verbessert (Überanpassung kontra. Genauigkeit im Testdatenset).\n",
    "\n",
    "Eine genauere Anleitung zum ```Cross Complexity Pruning``` findet ihr [hier](#anhang_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b>\n",
    "\n",
    "Die Werte von ```alpha``` sind wie folgt zu interpretieren:\n",
    "- 0: Der Entscheidungsbaum ist nicht geprunt (maximale Grösse)\n",
    "- je grösser ```alpha``` desto einfacher (weniger Blätter) ist der Entscheidungsbaum\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .cost_complexity_pruning_path(X_train, y_train) ist ein Algorithmus\n",
    "# der als Ergebniss wichtige 'alpha' Parameter liefert, welche es zu Überprüfen gilt\n",
    "path = clf_dt_e.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.00541298\n",
    "value_alpha = 0.00541298\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_new = DecisionTreeClassifier(random_state=0,\n",
    "                                    ccp_alpha=value_alpha)\n",
    "clf_dt_new.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_new,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 4:</b> \n",
    "\n",
    "Kontruiere und plote drei verschiedene Entscheidungsbäume mit verschiedenen 'alpha' Values. Für die Konstruktion kannst du den obigen Code verwenden bzw. kopieren.\n",
    "    \n",
    "Bitte stelle sicher, dass du die Entscheidungsbäume in den folgenden Variablen abspeicherst:\n",
    "- clf_dt_1\n",
    "- clf_dt_2\n",
    "- clf_dt_3\n",
    "\n",
    "-> Lösungen zu [Aufgabe 4](#lösung_aufgabe_4)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für den konstruierten Entscheidungsbaum 'clf_dt_new' wollen wir die Confusion-Matrix plotten, um zu sehen, wie gut er performt\n",
    "# Klasifizierungen\n",
    "predictions = clf_dt_new.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_new.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['keine HD', 'hat HD'])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 5:</b> \n",
    "\n",
    "Plote die Confusion-Matrix für die in Aufgabe 4 kosnstruierten Entscheidungsbäume. Für die Plots kannst du den obigen Code verwenden bzw. kopieren.\n",
    "<br>\n",
    "<br>-> Lösungen zu [Aufgabe 5](#lösung_aufgabe_5)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben jetzt gesehen, dass je nach ```alpha``` die Ergebnisse schlechter oder besser werden. Die Frage ist jetzt, wie finden wir auf eine einfache Art dasjenige 'alpha', bei welchem die Ergebnisse am besten sind.\n",
    "\n",
    "Wir schreiben einen Code der folgendes für uns erledigt:\n",
    "1. Einen Entscheidungsbaum pro ```alpha``` Wert konstruieren\n",
    "2. Pro Entscheidungsbaum die ```Accuracy``` für das Testset und das Trainingsset rechnen\n",
    "3. Die ```Accuracy``` für jeden Entscheidungsbaum in Abhängigkeit von ```alpha``` ploten\n",
    "\n",
    "Der Code, welcher dies für uns ausführt, findet ihr untenstehend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Komplexe Code-Zelle:</b> \n",
    "\n",
    "Die nachfolgenden Code-Zelle muss nur ausgeführt werden. Das Nachvollziehen der Funktionsweise ist nicht Teil dieser Einführung, dies würde über den Scope hinaus gehen.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit [:-1] entfernen wir den grössten 'alpha' Wert (das grösste 'alpha' hat keine Blätter)\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "clf_dts = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    clf_dts.append(clf_dt)\n",
    "    \n",
    "# mit dem untenstehenden Code plotten wir 'Accuracy' in Abhängigkeit zu 'alpha' (für Testdaten und Trainingsdaten)\n",
    "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
    "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle='steps-post')\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle='steps-post')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im obigen Plot finden wir die nötigen Informationen, welche wir brauchen, um das beste ```alpha``` zu finden.\n",
    "\n",
    "Von Interesse ist vor allem die orange Linie (```Testdaten```).\n",
    "\n",
    "Bei der Auswahl des besten ```alpha``` achten wir auf die folgenden zwei Punkte:\n",
    "1. Die ```Accuracy``` von ```test``` soll möglichst gross sein\n",
    "2. Die ```Accuracy``` von ```train``` soll möglichst gross sein\n",
    "\n",
    "Unter Anbetracht des aufgeführten Punktes, ist das optimale ```alpha``` also der sechsletzte Punkt auf der ```test``` Linie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um den sechsletzten Punkt zu finden rufen wir nochmals die Liste mit den 'alpha' Werten auf\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimales 'alpha'\n",
    "alpha_opt = 0.01081731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_pruned = DecisionTreeClassifier(random_state=42,\n",
    "                                       ccp_alpha=alpha_opt)\n",
    "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotte den Entscheidungsbaum\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plot_tree(clf_dt_pruned,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Accuracy' des neuen Entscheidungsbaumes\n",
    "predictions_new = clf_dt_pruned.predict(X_test)\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten die folgenden ```Accuracy-Werte```:\n",
    "* einfacher Entscheidungsbaum = ```0.786```\n",
    "* optimierter Entscheidungsbaum = ```0.746```\n",
    "\n",
    "Wenn wir diese beiden Werte vergleichen, sehen wir, dass wir durch die Optimierung einen Entscheidungsbaum erhalten haben, welcher besser mit neuen Beobachtungen umgehen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Abschluss (5 min) <a class=\"anchor\" id=\"sixth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was haben wir gelernt:\n",
    "* Was sind Entscheidungsbäume?\n",
    "* Wie lesen wir Entscheidungsbäume?\n",
    "* Wie bereiten wir Daten auf (fehlende Daten & Ausreisser)?\n",
    "* Arbeiten mit Trainings- und Testset\n",
    "* Erstellen von einfachen Entscheidungsbäumen\n",
    "* Optimieren von einfachen Entscheidungsbäumen\n",
    "* Accuracy und Confusion-Matrix\n",
    "\n",
    "Was muss man beachten, wenn man Modelle integrieren will:\n",
    "* Generalisierung\n",
    "* Software-Engineering-Skills um Modelle in Applikationen einzubinden\n",
    "* Antwortzeiten\n",
    "* Monitoren der Vorhersagequalität\n",
    "* Zusammenarbeit von mehreren Rollen (Data-Engineer, Data-Scientist, Software-Engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Anhang <a class=\"anchor\" id=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anhang_1'></a>\n",
    "### Anhang 1: Anleitung Cross Complexity Pruning\n",
    "\n",
    "Der Algorithmus zur Kostenkomplexitätsbeschneidung folgt in der Regel diesen Schritten:\n",
    "\n",
    "1. Erstelle einen anfänglichen Entscheidungsbaum mit einem Trainingsdatensatz unter Berücksichtigung aller verfügbaren Attribute und Merkmale.\n",
    "2. Bewerte die Klassifikationsleistung des Entscheidungsbaums anhand eines separaten Validierungsdatensatzes.\n",
    "3. Berechne für jeden internen Knoten des Entscheidungsbaums seine potenziellen Kosten in Bezug auf die fehlerhafte Klassifizierung oder andere Metriken.\n",
    "4. Weise jedem internen Knoten eine Kostenkomplexitätswertung zu, die in der Regel als Summe seiner Kosten für fehlerhafte Klassifizierung und eines Strafterms berechnet wird, der proportional zur Anzahl der absteigenden Blattknoten ist.\n",
    "5. Beginnend beim Wurzelknoten beschneide iterativ den Knoten mit der niedrigsten Kostenkomplexitätswertung und erstellen eine Reihe von kleineren Entscheidungsbäumen.\n",
    "6. Bewerte die Klassifikationsleistung jedes beschnittenen Entscheidungsbaums anhand des Validierungsdatensatzes.\n",
    "7. Wähle den beschnittenen Baum mit der besten Leistung aus, die oft anhand der Genauigkeit oder einer anderen geeigneten Metrik gemessen wird.\n",
    "8. Optional kann man den ausgewählten Baum weiter beschneiden, indem man den Komplexitätsparameter α optimiert und die Schritte 5-7 wiederholt.\n",
    "9. Der endgültige beschnittene Entscheidungsbaum wird erzielt, wenn durch zusätzliches Beschneiden keine weiteren Verbesserungen der Leistung erzielt werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Lösungen <a class=\"anchor\" id=\"eight-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lösung_aufgabe_1'></a>\n",
    "### Lösung Aufgabe 1\n",
    "\n",
    "Klassen:\n",
    "- Datenobjekt 1 = 'Has Insurance'\n",
    "- Datenobjekt 2 = 'Has Insurance' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/Lösung_mit_Pfaden.png \"Lösung\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lösung_aufgabe_2'></a>\n",
    "### Lösung Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lösung_aufgabe_3'></a>\n",
    "### Lösung Aufgabe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing = df_start[df_start['ca'] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lösung_aufgabe_4'></a>\n",
    "### Lösung  Aufgabe 4\n",
    "\n",
    "Die folgenden Code-Zellen bilden eine mögliche Lösung zu Aufgabe 4 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.00557903\n",
    "value_alpha = 0.0000000000001\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_1 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_1.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_1,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X_encoded.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.00557903\n",
    "value_alpha = 0.01425422\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_2 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_2.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_2,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X_encoded.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.00557903\n",
    "value_alpha = 0.2\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_3 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_3.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_3,\n",
    "          filled=True,\n",
    "          class_names=[\"keine HD\", \"hat HD\"],\n",
    "          feature_names=X_encoded.columns)\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lösung_aufgabe_5'></a>\n",
    "### Lösung  Aufgabe 5\n",
    "Die folgenden Code-Zellen bilden eine mögliche Lösung zu Aufgabe 5 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_1.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_2.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_3.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"keine HD\", \"hat HD\"])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Quellen <a class=\"anchor\" id=\"nineth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#169; Quellen:\n",
    "&#128190; **Daten:** https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/\n",
    "<br>\n",
    "&#128252;  **Video:** https://youtu.be/q90UDEgYqeI?list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB\n",
    "\n",
    "### &#128161; Weitere Informationen:\n",
    "\n",
    "``` Decision Trees: ``` &nbsp; https://www.youtube.com/watch?v=7VeUPuFGJHk&t=0s\n",
    "<br>\n",
    "``` Cross Validation: ``` &nbsp; https://www.youtube.com/watch?v=fSytzGwwBVw&t=0s\n",
    "<br>\n",
    "``` Confusion Matrix: ``` &nbsp; https://www.youtube.com/watch?v=Kdsp6soqA7o&t=0s\n",
    "<br>\n",
    "``` Cost-Complexity Pruning: ``` &nbsp; https://www.youtube.com/watch?v=D0efHEJsfHo&t=0s\n",
    "<br>\n",
    "``` Bias and Variance and Overfitting: ``` &nbsp; https://www.youtube.com/watch?v=EuBBz3bI-aA&t=0s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
